{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sports-recognition-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc71RZ890SLB",
        "colab_type": "text"
      },
      "source": [
        "## Test del tool su "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFdYumtNqaWp",
        "colab_type": "code",
        "outputId": "30386c71-45bd-412f-a2b0-cdaf8717730e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "! git clone https://github.com/Meyke/ProgettoSIIML.git\n",
        "! git clone --recursive https://github.com/metalbubble/TRN-pytorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ProgettoSIIML'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)   \u001b[K\rremote: Counting objects:  10% (2/20)   \u001b[K\rremote: Counting objects:  15% (3/20)   \u001b[K\rremote: Counting objects:  20% (4/20)   \u001b[K\rremote: Counting objects:  25% (5/20)   \u001b[K\rremote: Counting objects:  30% (6/20)   \u001b[K\rremote: Counting objects:  35% (7/20)   \u001b[K\rremote: Counting objects:  40% (8/20)   \u001b[K\rremote: Counting objects:  45% (9/20)   \u001b[K\rremote: Counting objects:  50% (10/20)   \u001b[K\rremote: Counting objects:  55% (11/20)   \u001b[K\rremote: Counting objects:  60% (12/20)   \u001b[K\rremote: Counting objects:  65% (13/20)   \u001b[K\rremote: Counting objects:  70% (14/20)   \u001b[K\rremote: Counting objects:  75% (15/20)   \u001b[K\rremote: Counting objects:  80% (16/20)   \u001b[K\rremote: Counting objects:  85% (17/20)   \u001b[K\rremote: Counting objects:  90% (18/20)   \u001b[K\rremote: Counting objects:  95% (19/20)   \u001b[K\rremote: Counting objects: 100% (20/20)   \u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 903 (delta 9), reused 15 (delta 8), pack-reused 883\u001b[K\n",
            "Receiving objects: 100% (903/903), 141.53 MiB | 31.91 MiB/s, done.\n",
            "Resolving deltas: 100% (224/224), done.\n",
            "Cloning into 'TRN-pytorch'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 263 (delta 0), reused 6 (delta 0), pack-reused 257\u001b[K\n",
            "Receiving objects: 100% (263/263), 69.11 KiB | 3.64 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n",
            "Submodule 'model_zoo' (https://github.com/yjxiong/tensorflow-model-zoo.torch) registered for path 'model_zoo'\n",
            "Cloning into '/content/TRN-pytorch/model_zoo'...\n",
            "remote: Enumerating objects: 621, done.        \n",
            "remote: Total 621 (delta 0), reused 0 (delta 0), pack-reused 621        \n",
            "Receiving objects: 100% (621/621), 43.66 MiB | 28.55 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n",
            "Submodule path 'model_zoo': checked out 'e31e0b7aa451e2c12c0107e616953a03d8cd0d47'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIBbz8M-qmb7",
        "colab_type": "code",
        "outputId": "4554078f-cef8-4079-a8c5-f0b82e7b48ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "% cd /content/ProgettoSIIML/deeplearning/sports_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ProgettoSIIML/deeplearning/sports_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qShBBVT3qnEm",
        "colab_type": "code",
        "outputId": "9aa4dadb-2115-4683-d65d-834e74873987",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#@title\n",
        "import csv\n",
        "with open('sports1.csv') as file1:\n",
        "    reader1 = csv.reader(file1)\n",
        "    sports1 = {rows[0]:rows[1] for rows in reader1}\n",
        "with open('sports2.csv') as file2:\n",
        "    reader2 = csv.reader(file2)\n",
        "    sports2 = {rows[0]:rows[1] for rows in reader2}\n",
        "with open('videos.csv') as file3:\n",
        "    reader3 = csv.reader(file3)\n",
        "    videos = {rows[0]:rows[1].title() for rows in reader3}\n",
        "print(videos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'https://www.youtube.com/watch?v=1XHhmGVJn4U': 'Cycling', 'https://www.youtube.com/watch?v=W4LG1AglioQ': 'Cycling', 'https://www.youtube.com/watch?v=KoI81CdYEa8': 'Cycling', 'https://www.youtube.com/watch?v=6FWeSVv8UVs': 'Cycling', 'https://www.youtube.com/watch?v=H52FAOBfbV8': 'Cycling', 'https://www.youtube.com/watch?v=UbVoAIaLCak': 'Cycling', 'https://www.youtube.com/watch?v=Q13D3qe7veY': 'Cycling', 'https://www.youtube.com/watch?v=XFfOUGTUuzc': 'Cycling', 'https://www.youtube.com/watch?v=-NRvACRKDCQ': 'Cycling', 'https://www.youtube.com/watch?v=uDtdXmS2KiE': 'Cycling', 'https://www.youtube.com/watch?v=l0SFfiAPTE0': 'Cycling', 'https://www.youtube.com/watch?v=WqpVpSnmHMU': 'Cycling', 'https://www.youtube.com/watch?v=qI3Pm4YIn8o': 'Cycling', 'https://www.youtube.com/watch?v=14mASFd0J44': 'Cycling', 'https://www.youtube.com/watch?v=nSW_mm3dgv8': 'Cycling', 'https://www.youtube.com/watch?v=OCG43Jf-Gq0': 'Cycling', 'https://www.youtube.com/watch?v=EewTm3UoPHw': 'Cycling', 'https://www.youtube.com/watch?v=7AfeLtZZWlQ': 'Cycling', 'https://www.youtube.com/watch?v=KDVHfRNR8x8': 'Cycling', 'https://www.youtube.com/watch?v=ibmCx8CkVCQ': 'Cycling'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_7vPAtOqqtK",
        "colab_type": "code",
        "outputId": "252a4690-4540-403f-8c46-3d182a2f3169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "% cd /content/TRN-pytorch/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TRN-pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONdi3vpqs3N",
        "colab_type": "code",
        "outputId": "2e653898-0d91-4a81-9100-03a1b963d8b2",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "source": [
        "#@title\n",
        "% cd pretrain\n",
        "! ./download_models.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TRN-pytorch/pretrain\n",
            "Downloading TRNmultiscale on Something-Something\n",
            "--2019-04-14 17:11:00--  http://relation.csail.mit.edu/models/TRN_something_RGB_BNInception_TRNmultiscale_segment8_best.pth.tar\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52711275 (50M) [application/x-tar]\n",
            "Saving to: ‘TRN_something_RGB_BNInception_TRNmultiscale_segment8_best.pth.tar’\n",
            "\n",
            "TRN_something_RGB_B 100%[===================>]  50.27M  72.2MB/s    in 0.7s    \n",
            "\n",
            "2019-04-14 17:11:01 (72.2 MB/s) - ‘TRN_something_RGB_BNInception_TRNmultiscale_segment8_best.pth.tar’ saved [52711275/52711275]\n",
            "\n",
            "--2019-04-14 17:11:01--  http://relation.csail.mit.edu/models/TRN_something_RGB_BNInception_TRN_segment3_best.pth.tar\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44205389 (42M) [application/x-tar]\n",
            "Saving to: ‘TRN_something_RGB_BNInception_TRN_segment3_best.pth.tar’\n",
            "\n",
            "TRN_something_RGB_B 100%[===================>]  42.16M  56.4MB/s    in 0.7s    \n",
            "\n",
            "2019-04-14 17:11:02 (56.4 MB/s) - ‘TRN_something_RGB_BNInception_TRN_segment3_best.pth.tar’ saved [44205389/44205389]\n",
            "\n",
            "--2019-04-14 17:11:02--  http://relation.csail.mit.edu/models/something_categories.txt\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7600 (7.4K) [text/plain]\n",
            "Saving to: ‘something_categories.txt’\n",
            "\n",
            "something_categorie 100%[===================>]   7.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-14 17:11:02 (275 MB/s) - ‘something_categories.txt’ saved [7600/7600]\n",
            "\n",
            "Downloading TRNmultiscale on Jester\n",
            "--2019-04-14 17:11:02--  http://relation.csail.mit.edu/models/TRN_jester_RGB_BNInception_TRNmultiscale_segment8_best.pth.tar\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51653477 (49M) [application/x-tar]\n",
            "Saving to: ‘TRN_jester_RGB_BNInception_TRNmultiscale_segment8_best.pth.tar’\n",
            "\n",
            "TRN_jester_RGB_BNIn 100%[===================>]  49.26M  65.4MB/s    in 0.8s    \n",
            "\n",
            "2019-04-14 17:11:03 (65.4 MB/s) - ‘TRN_jester_RGB_BNInception_TRNmultiscale_segment8_best.pth.tar’ saved [51653477/51653477]\n",
            "\n",
            "--2019-04-14 17:11:03--  http://relation.csail.mit.edu/models/jester_categories.txt\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527 [text/plain]\n",
            "Saving to: ‘jester_categories.txt’\n",
            "\n",
            "jester_categories.t 100%[===================>]     527  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-14 17:11:03 (68.3 MB/s) - ‘jester_categories.txt’ saved [527/527]\n",
            "\n",
            "Downloading TRNmultiscale on Moments in Time\n",
            "--2019-04-14 17:11:03--  http://relation.csail.mit.edu/models/TRN_moments_RGB_InceptionV3_TRNmultiscale_segment8_best.pth.tar\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101160240 (96M) [application/x-tar]\n",
            "Saving to: ‘TRN_moments_RGB_InceptionV3_TRNmultiscale_segment8_best.pth.tar’\n",
            "\n",
            "TRN_moments_RGB_Inc 100%[===================>]  96.47M  75.0MB/s    in 1.3s    \n",
            "\n",
            "2019-04-14 17:11:04 (75.0 MB/s) - ‘TRN_moments_RGB_InceptionV3_TRNmultiscale_segment8_best.pth.tar’ saved [101160240/101160240]\n",
            "\n",
            "--2019-04-14 17:11:04--  http://relation.csail.mit.edu/models/moments_categories.txt\n",
            "Resolving relation.csail.mit.edu (relation.csail.mit.edu)... 128.30.100.255\n",
            "Connecting to relation.csail.mit.edu (relation.csail.mit.edu)|128.30.100.255|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3079 (3.0K) [text/plain]\n",
            "Saving to: ‘moments_categories.txt’\n",
            "\n",
            "moments_categories. 100%[===================>]   3.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-14 17:11:04 (397 MB/s) - ‘moments_categories.txt’ saved [3079/3079]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvVooU8_qwtN",
        "colab_type": "code",
        "outputId": "20657e1d-ac75-4fcb-aace-a054f99278b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "% cd /content/TRN-pytorch/model_zoo/bninception"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TRN-pytorch/model_zoo/bninception\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5MCUxaIqzPW",
        "colab_type": "code",
        "outputId": "b3506a9e-3305-44ba-d427-5dc3c979f9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile pytorch_load.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from .layer_factory import get_basic_layer, parse_expr\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import yaml\n",
        "\n",
        "\n",
        "class BNInception(nn.Module):\n",
        "    def __init__(self, model_path='model_zoo/bninception/bn_inception.yaml', num_classes=101,\n",
        "                       weight_url='https://yjxiong.blob.core.windows.net/models/bn_inception-9f5701afb96c8044.pth'):\n",
        "        super(BNInception, self).__init__()\n",
        "\n",
        "        manifest = yaml.load(open(model_path))\n",
        "\n",
        "        layers = manifest['layers']\n",
        "\n",
        "        self._channel_dict = dict()\n",
        "\n",
        "        self._op_list = list()\n",
        "        for l in layers:\n",
        "            out_var, op, in_var = parse_expr(l['expr'])\n",
        "            if op != 'Concat':\n",
        "                id, out_name, module, out_channel, in_name = get_basic_layer(l,\n",
        "                                                                3 if len(self._channel_dict) == 0 else self._channel_dict[in_var[0]],\n",
        "                                                                             conv_bias=True)\n",
        "\n",
        "                self._channel_dict[out_name] = out_channel\n",
        "                setattr(self, id, module)\n",
        "                self._op_list.append((id, op, out_name, in_name))\n",
        "            else:\n",
        "                self._op_list.append((id, op, out_var[0], in_var))\n",
        "                channel = sum([self._channel_dict[x] for x in in_var])\n",
        "                self._channel_dict[out_var[0]] = channel\n",
        "\n",
        "        #self.load_state_dict(torch.utils.model_zoo.load_url(weight_url))\n",
        "\n",
        "    def forward(self, input):\n",
        "        data_dict = dict()\n",
        "        data_dict[self._op_list[0][-1]] = input\n",
        "\n",
        "        def get_hook(name):\n",
        "\n",
        "            def hook(m, grad_in, grad_out):\n",
        "                print(name, grad_out[0].data.abs().mean())\n",
        "\n",
        "            return hook\n",
        "        for op in self._op_list:\n",
        "            if op[1] != 'Concat' and op[1] != 'InnerProduct':\n",
        "                data_dict[op[2]] = getattr(self, op[0])(data_dict[op[-1]])\n",
        "                # getattr(self, op[0]).register_backward_hook(get_hook(op[0]))\n",
        "            elif op[1] == 'InnerProduct':\n",
        "                x = data_dict[op[-1]]\n",
        "                data_dict[op[2]] = getattr(self, op[0])(x.view(x.size(0), -1))\n",
        "            else:\n",
        "                try:\n",
        "                    data_dict[op[2]] = torch.cat(tuple(data_dict[x] for x in op[-1]), 1)\n",
        "                except:\n",
        "                    for x in op[-1]:\n",
        "                        print(x,data_dict[x].size())\n",
        "                    raise\n",
        "        return data_dict[self._op_list[-1][2]]\n",
        "\n",
        "\n",
        "class InceptionV3(BNInception):\n",
        "    def __init__(self, model_path='model_zoo/bninception/inceptionv3.yaml', num_classes=101,\n",
        "                 weight_url='https://yjxiong.blob.core.windows.net/models/inceptionv3-cuhk-0e09b300b493bc74c.pth'):\n",
        "        super(InceptionV3, self).__init__(model_path=model_path, weight_url=weight_url, num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting pytorch_load.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcylM-rfq3Ig",
        "colab_type": "code",
        "outputId": "b0d11854-5fe5-43a5-9b1d-6401e4cc4cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/TRN-pytorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TRN-pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcXDatLiq5qB",
        "colab_type": "code",
        "outputId": "e4970e07-b149-4e30-9ece-0c5a24f12b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install pafy\n",
        "!pip install youtube_dl\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pafy\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "\n",
        "import json\n",
        "import re\n",
        "import argparse\n",
        "import functools\n",
        "import subprocess\n",
        "import moviepy.editor as mpy\n",
        "import ast\n",
        "import torchvision\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "from models import TSN\n",
        "import transforms\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pafy\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/e8/3516f761558525b00d3eaf73744eed5c267db20650b7b660674547e3e506/pafy-0.5.4-py2.py3-none-any.whl\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.4\n",
            "Collecting youtube_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/d5/f3f7ff7fc4d05ba2b6d5904f21b43a625c3681e02fb620bcf789316d6664/youtube_dl-2019.4.7-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.8MB 4.6MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2019.4.7\n",
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1949696/45929032 bytes (4.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5652480/45929032 bytes (12.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9175040/45929032 bytes (20.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12935168/45929032 bytes (28.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16637952/45929032 bytes (36.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20389888/45929032 bytes (44.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24059904/45929032 bytes (52.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27820032/45929032 bytes (60.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31440896/45929032 bytes (68.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35192832/45929032 bytes (76.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38969344/45929032 bytes (84.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42655744/45929032 bytes (92.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-MSEd547CW",
        "colab_type": "code",
        "outputId": "9e540252-4408-4d53-e8de-3368180d3368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def extract_frames(video_file, num_frames=8):\n",
        "      try:\n",
        "          os.makedirs(os.path.join(os.getcwd(), 'frames'))\n",
        "      except OSError:\n",
        "          pass\n",
        "\n",
        "      output = subprocess.Popen(['ffmpeg', '-i', video_file],\n",
        "                                stderr=subprocess.PIPE).communicate()\n",
        "      # Search and parse 'Duration: 00:05:24.13,' from ffmpeg stderr.\n",
        "      re_duration = re.compile('Duration: (.*?)\\.')\n",
        "      duration = re_duration.search(str(output[1])).groups()[0]\n",
        "      temp = [int(i) for i in duration.split(\":\")]\n",
        "\n",
        "      seconds = functools.reduce(lambda x, y: x * 60 + y,\n",
        "                                 temp)\n",
        "      rate = num_frames / float(seconds)\n",
        "\n",
        "      output = subprocess.Popen(['ffmpeg', '-i', video_file,\n",
        "                                 '-vf', 'fps={}'.format(rate),\n",
        "                                 '-vframes', str(num_frames),\n",
        "                                 '-loglevel', 'panic',\n",
        "                                 'frames/%d.jpg']).communicate()\n",
        "      frame_paths = sorted([os.path.join('frames', frame)\n",
        "                            for frame in os.listdir('frames')])\n",
        "\n",
        "      frames = load_frames(frame_paths)\n",
        "      subprocess.call(['rm', '-rf', 'frames'])\n",
        "      return frames\n",
        "\n",
        "\n",
        "def load_frames(frame_paths, num_frames=8):\n",
        "    frames = [Image.open(frame).convert('RGB') for frame in frame_paths]\n",
        "    if len(frames) >= num_frames:\n",
        "        return frames[::int(np.ceil(len(frames) / float(num_frames)))]\n",
        "    else:\n",
        "        raise ValueError('Video must have at least {} frames'.format(num_frames))\n",
        "\n",
        "\n",
        "def render_frames(frames, prediction):\n",
        "    rendered_frames = []\n",
        "    for frame in frames:\n",
        "        img = np.array(frame)\n",
        "        height, width, _ = img.shape\n",
        "        cv2.putText(img, prediction,\n",
        "                    (1, int(height / 8)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    1, (255, 255, 255), 2)\n",
        "        rendered_frames.append(img)\n",
        "    return rendered_frames\n",
        "\n",
        "def get_result(results):\n",
        "    for result in results:\n",
        "      if sports1.get(result) != None:\n",
        "        return sports1.get(result)\n",
        "    for result in results:\n",
        "      if sports2.get(result) != None:\n",
        "        return sports2.get(result)\n",
        "\n",
        "# Get dataset categories.\n",
        "categories_file = 'pretrain/moments_categories.txt'\n",
        "categories = [line.rstrip() for line in open(categories_file, 'r').readlines()]\n",
        "num_class = len(categories)\n",
        "\n",
        "arch = 'InceptionV3'\n",
        "\n",
        "# Load model.\n",
        "net = TSN(num_class,\n",
        "          8,\n",
        "          'RGB',\n",
        "          base_model= arch,\n",
        "          consensus_type='TRNmultiscale',\n",
        "          img_feature_dim=256, print_spec=False)\n",
        "\n",
        "checkpoint = torch.load('pretrain/TRN_moments_RGB_InceptionV3_TRNmultiscale_segment8_best.pth.tar')\n",
        "base_dict = {'.'.join(k.split('.')[1:]): v for k, v in list(checkpoint['state_dict'].items())}\n",
        "net.load_state_dict(base_dict)\n",
        "net.cuda().eval()\n",
        "\n",
        "# Initialize frame transforms.\n",
        "transform = torchvision.transforms.Compose([\n",
        "    transforms.GroupOverSample(net.input_size, net.scale_size),\n",
        "    transforms.Stack(roll=(arch in ['BNInception', 'InceptionV3'])),\n",
        "    transforms.ToTorchFormatTensor(div=(arch not in ['BNInception', 'InceptionV3'])),\n",
        "    transforms.GroupNormalize(net.input_mean, net.input_std),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi-Scale Temporal Relation Network Module in use ['8-frame relation', '7-frame relation', '6-frame relation', '5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']\n",
            "Freezing BatchNorm2D except the first one.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m_OS9nv0-Y9",
        "colab_type": "code",
        "outputId": "a76eabf1-17a0-4991-c356-d61cd86312ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "corretti = 0\n",
        "errati = 0\n",
        "non_riconosciuti = 0\n",
        "eccezzioni = 0\n",
        "for key, value in videos.items():\n",
        "  try:\n",
        "      url = key\n",
        "      vPafy = pafy.new(url)\n",
        "      play = vPafy.getbest()\n",
        "      video = play.download(filepath=\"video.mp4\")\n",
        "\n",
        "\n",
        "      # Obtain video frames\n",
        "      frames = extract_frames(\"video.mp4\", 8)\n",
        "\n",
        "\n",
        "      # Make video prediction.\n",
        "      data = transform(frames)\n",
        "      input = data.view(-1, 3, data.size(1), data.size(2)).unsqueeze(0).cuda()\n",
        "\n",
        "      with torch.no_grad():\n",
        "          logits = net(input)\n",
        "          h_x = torch.mean(F.softmax(logits, 1), dim=0).data\n",
        "          probs, idx = h_x.sort(0, True)\n",
        "\n",
        "      # Output the prediction.\n",
        "      video_name = \"video\"\n",
        "      predictions = []\n",
        "      for i in range(0, 3):\n",
        "          predictions.append(categories[idx[i]])\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "      if get_result(predictions) != None:\n",
        "        if value == ast.literal_eval(get_result(predictions))[0]:\n",
        "          corretti += 1\n",
        "        else:\n",
        "          errati += 1\n",
        "      else:\n",
        "        non_riconosciuti += 1\n",
        "      \n",
        "#      print(\"Corretti sono: \" +str(corretti) + \" Errati sono: \" + str(errati) \n",
        "#            + \" Non riconosciuti sono: \" + str(non_riconosciuti) + \" Eccezzioni sono: \" + str(eccezzioni))\n",
        "  except:\n",
        "      eccezzioni += 1\n",
        "      continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXccRbeLN4_p",
        "colab_type": "code",
        "outputId": "99d72f61-36d4-4fec-b023-9b1ff7e4271a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Corretti sono: \" +str(corretti) + \", Errati sono: \" + str(errati) \n",
        "      + \", Non riconosciuti sono: \" + str(non_riconosciuti) + \", Eccezzioni sono: \" + str(eccezzioni))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corretti sono: 19 Errati sono: 0 Non riconosciuti sono: 0 Eccezzioni sono: 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}